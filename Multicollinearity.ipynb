{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 2)\n",
      "     FG%   TRB\n",
      "0  0.495  44.4\n",
      "1  0.462  44.4\n",
      "2  0.469  46.4\n",
      "3  0.470  43.7\n",
      "4  0.475  42.9\n",
      "(31, 1)\n",
      "     PTS\n",
      "0  115.9\n",
      "1  115.3\n",
      "2  111.7\n",
      "3  110.3\n",
      "4  109.2\n",
      "(2, 2)\n",
      "(2, 1)\n",
      "[[165.62627359]\n",
      " [  0.68661008]]\n",
      "(31, 4)\n",
      "     FG%   TRB   ORB   DRB\n",
      "0  0.495  44.4   9.4  35.0\n",
      "1  0.462  44.4  10.9  33.5\n",
      "2  0.469  46.4  11.8  34.6\n",
      "3  0.470  43.7   9.3  34.4\n",
      "4  0.475  42.9  10.3  32.6\n",
      "(31, 1)\n",
      "     PTS\n",
      "0  115.9\n",
      "1  115.3\n",
      "2  111.7\n",
      "3  110.3\n",
      "4  109.2\n",
      "(4, 1)\n",
      "[[162.50999666]\n",
      " [  2.72389866]\n",
      " [ -2.09926029]\n",
      " [ -1.97635997]]\n",
      "Due to the fact that the result to TRB data coefficient is really high \n",
      "stands for multicollinearity(predictors are highly correlated. Thus, if you get Betas high you should generally try to reduce your multicollinearity.)\n"
     ]
    }
   ],
   "source": [
    "#Nick Gundobin 110805377\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#import entire 2017 data\n",
    "data = pd.read_csv('/Users/nickgun1984/team_stats_per_game_2017.csv')\n",
    "# QUESTION A\n",
    "X = data[['FG%','TRB']]\n",
    "#ones = np.ones([X.shape[0],1])\n",
    "#X = np.concatenate((ones,X),axis=1)\n",
    "print(X.shape)\n",
    "print(X.head())\n",
    "\n",
    "y = data[['PTS']]\n",
    "print(y.shape)\n",
    "print(y.head())\n",
    "\n",
    "X_transpose = np.transpose(X)\n",
    "#print(X_transpose)\n",
    "product = np.dot(X_transpose,X)\n",
    "print(product.shape)\n",
    "inverse = np.linalg.inv(product)\n",
    "product1 = np.dot(inverse,X_transpose)\n",
    "#print(product1)\n",
    "result = np.dot(product1,y)  \n",
    "print(result.shape)\n",
    "print(result)\n",
    "\n",
    "#QUESTION B\n",
    "X = data[['FG%','TRB', 'ORB','DRB']]\n",
    "#ones = np.ones([X.shape[0],1])\n",
    "#X = np.concatenate((ones,X),axis=1)\n",
    "print(X.shape)\n",
    "print(X.head())\n",
    "\n",
    "y = data[['PTS']]\n",
    "print(y.shape)\n",
    "print(y.head())\n",
    "\n",
    "X_transpose = np.transpose(X)\n",
    "#print(X_transpose.shape)\n",
    "product = np.dot(X_transpose,X)\n",
    "#print(product.shape)\n",
    "inverse = np.linalg.inv(product)\n",
    "product1 = np.dot(inverse,X_transpose)\n",
    "#print(product1.shape)\n",
    "result = np.dot(product1,y)  \n",
    "print(result.shape)\n",
    "print(result)\n",
    "print(\"Due to the fact that the result to TRB data coefficient is really high \")\n",
    "print(\"stands for multicollinearity(predictors are highly correlated. Thus, if you get Betas high you should generally try to reduce your multicollinearity.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE and MAPE for CASE 1:\n",
      "SSE is 139.50638605580562\n",
      "MAPE is 1.4874577869982384\n",
      "None\n",
      "/////////////////////////////////////////\n",
      "SSE and MAPE for CASE 2:\n",
      "SSE is 200.85118430234544\n",
      "MAPE is 1.843552956637524\n",
      "None\n",
      "/////////////////////////////////////////\n",
      "SSE and MAPE for CASE 3:\n",
      "SSE is 698.4700154206722\n",
      "MAPE is 3.927363202888639\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:78: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def sse_mape(X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    #Beta(Ordinary Least Squares)\n",
    "    X_transpose = np.transpose(X_train)\n",
    "    #print(X_transpose)\n",
    "    product = np.dot(X_transpose,X_train)\n",
    "    #print(product.shape)\n",
    "    inverse = np.linalg.inv(product)\n",
    "    product1 = np.dot(inverse,X_transpose)\n",
    "    #print(product1)\n",
    "    result = np.dot(product1,y_train)  \n",
    "    #print(result)\n",
    "\n",
    "    y_pred = np.dot(X_test,result)\n",
    "\n",
    "    #Finding Sum of Squared Error\n",
    "    sse = 0\n",
    "    for i in range(31):\n",
    "        sse += (y_pred[i] - y_test[i])**2\n",
    "    print(\"SSE is \"+str(np.asscalar(sse)))\n",
    "\n",
    "    #Finding MAPE --- Mean Absolute Percentage Error\n",
    "    mape = 0\n",
    "    for i in range(31):\n",
    "        mape += ((((np.abs(y_test[i] - y_pred[i]))/y_test[i]))/31)*100\n",
    "    print(\"MAPE is \"+str(np.asscalar(mape)))\n",
    "    \n",
    "#QUESTION C\n",
    "#(i)\n",
    "test_data_2018 = pd.read_csv('/Users/nickgun1984/test_data.csv')\n",
    "train_data_2017 = pd.read_csv('/Users/nickgun1984/team_stats_per_game_2017.csv')\n",
    "\n",
    "#Training Data\n",
    "X_train = train_data_2017[['FG%','TRB']]\n",
    "y_train = train_data_2017[['PTS']]\n",
    "\n",
    "#Test Data for (i),(ii),(iii)\n",
    "X_test = test_data_2018[['FG%','TRB']]\n",
    "y_test = test_data_2018[['PTS']].values\n",
    "\n",
    "#print(y.shape)\n",
    "#print(y.head())\n",
    "print(\"SSE and MAPE for CASE 1:\")\n",
    "print(sse_mape(X_train,y_train,X_test,y_test))\n",
    "print(\"/////////////////////////////////////////\")\n",
    "\n",
    "#Data for Question C\n",
    "#(ii)\n",
    "train_data_2016 = pd.read_csv('/Users/nickgun1984/train_set_2016.csv')\n",
    "train_data_2017_1 = train_data_2017[['FG%','TRB','PTS']]\n",
    "frames = [train_data_2016,train_data_2017_1]\n",
    "merged_data = pd.concat(frames)\n",
    "\n",
    "#Training Data\n",
    "X_train_1 = merged_data[['FG%','TRB']]\n",
    "y_train_1 = merged_data[['PTS']]\n",
    "#print(X_train_1.shape)\n",
    "\n",
    "print(\"SSE and MAPE for CASE 2:\")\n",
    "print(sse_mape(X_train_1,y_train_1,X_test,y_test))\n",
    "print(\"/////////////////////////////////////////\")\n",
    "\n",
    "#Data for Question C\n",
    "#(iii)\n",
    "train_data_2010 = pd.read_csv('/Users/nickgun1984/train_set_2010.csv')\n",
    "train_data_2011 = pd.read_csv('/Users/nickgun1984/train_set_2011.csv')\n",
    "train_data_2012 = pd.read_csv('/Users/nickgun1984/train_set_2012.csv')\n",
    "train_data_2013 = pd.read_csv('/Users/nickgun1984/train_set_2013.csv')\n",
    "train_data_2014 = pd.read_csv('/Users/nickgun1984/train_set_2014.csv')\n",
    "train_data_2015 = pd.read_csv('/Users/nickgun1984/train_set_2015.csv')\n",
    "train_data_2016 = pd.read_csv('/Users/nickgun1984/train_set_2016.csv')\n",
    "\n",
    "train_data = train_data_2017[['FG%','TRB','PTS']]\n",
    "frames = [train_data_2016,train_data_2017,train_data_2010,train_data_2011,train_data_2012,train_data_2013,train_data_2014,train_data_2015]\n",
    "merged_data1 = pd.concat(frames)\n",
    "\n",
    "#Training Data\n",
    "X_train_2 = merged_data1[['FG%','TRB']]\n",
    "y_train_2 = merged_data1[['PTS']]\n",
    "#print(X_train_2.shape)\n",
    "\n",
    "print(\"SSE and MAPE for CASE 3:\")\n",
    "print(sse_mape(X_train_2,y_train_2,X_test,y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
